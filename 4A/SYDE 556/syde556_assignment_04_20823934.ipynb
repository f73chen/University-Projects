{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SYDE 556/750 --- Assignment 4\n",
    "**Student ID: 20823934**\n",
    "\n",
    "*Note:* Please include your numerical student ID only, do *not* include your name.\n",
    "\n",
    "*Note:* Refer to the [PDF](https://github.com/celiasmith/syde556-f22/raw/master/assignments/assignment_04/syde556_assignment_04.pdf) for the full instructions (including some hints), this notebook contains abbreviated instructions only. Cells you need to fill out are marked with a \"writing hand\" symbol. Of course, you can add new cells in between the instructions, but please leave the instructions intact to facilitate marking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import numpy and matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import nengo and some helper functions for Q1\n",
    "import nengo\n",
    "from nengo.utils.ensemble import tuning_curves\n",
    "from nengo.utils.connection import eval_point_decoding\n",
    "\n",
    "# Fix the numpy random seed for reproducible results\n",
    "np.random.seed(18945)\n",
    "\n",
    "# Some formating options\n",
    "%config InlineBackend.figure_formats = ['svg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "sig = inspect.signature(nengo.Ensemble)\n",
    "for param in sig.parameters.values():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Building an ensemble of neurons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**a) Tuning curves.** Plot the population tuning curves. Plot the representation accuracy plot ($x - \\hat{x}$). Compute and report the RMSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q1_ensemble(tau_rc=0.02, tau_ref=0.002, radius=1, seed=0):\n",
    "    # Generate the 1D network\n",
    "    model = nengo.Network()\n",
    "    with model:\n",
    "        a = nengo.Ensemble(n_neurons=100,                                   # 100 neurons\n",
    "                           dimensions=1,                                    # 1-dimensional space\n",
    "                           intercepts=nengo.dists.Uniform(-1, 1),           # x-intercepts between -1 and 1\n",
    "                           max_rates=nengo.dists.Uniform(100, 200),         # max firing rates between 100 and 200 Hz\n",
    "                           neuron_type=nengo.neurons.LIF(tau_rc=tau_rc, \n",
    "                                                         tau_ref=tau_ref),  # LIF neurons\n",
    "                           radius=radius,                                   # radius\n",
    "                           seed=seed)                                       # random seed\n",
    "        \n",
    "        a_a = nengo.Connection(pre=a, post=a)\n",
    "\n",
    "    # Simulate the tuning curves\n",
    "    with nengo.Simulator(model) as sim:\n",
    "        tuning_x, activities = tuning_curves(a, sim)\n",
    "\n",
    "    # Calculate the representation accuracy and sort them by eval_points\n",
    "    eval_points, targets, decoded = eval_point_decoding(a_a, sim, eval_points=None)\n",
    "    sorted_zipped = sorted(zip(eval_points, targets, decoded), key=lambda x: x[0])\n",
    "    eval_points, targets, decoded = zip(*sorted_zipped)\n",
    "    eval_points = np.array(eval_points)\n",
    "    targets = np.array(targets)\n",
    "    decoded = np.array(decoded)\n",
    "\n",
    "    # Compute the RMSE\n",
    "    rmse = np.sqrt(np.mean((targets - decoded)**2))\n",
    "\n",
    "    return tuning_x, activities, targets, decoded, rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q1a():\n",
    "    tuning_x, activities, targets, decoded, rmse = q1_ensemble()\n",
    "\n",
    "    # Plot the tuning curves\n",
    "    plt.figure()\n",
    "    plt.plot(tuning_x, activities)\n",
    "    plt.title(\"Tuning curves for 100 neurons\")\n",
    "    plt.xlabel(\"Input x\")\n",
    "    plt.ylabel(\"Firing rate (Hz)\")\n",
    "    plt.show()\n",
    "\n",
    "    # Plot the representation accuracy\n",
    "    plt.figure()\n",
    "    plt.plot(targets, targets - decoded)\n",
    "    plt.title(\"Representation accuracy (x - x_hat)\")\n",
    "    plt.xlabel(\"Input x\")\n",
    "    plt.ylabel(\"x - x_hat\")\n",
    "    plt.show()\n",
    "    \n",
    "    # Report the RMSE\n",
    "    print(\"RMSE: %0.3f\" % rmse)\n",
    "\n",
    "q1a()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b) RMSE and radius.** Compute the RMSE for (at least) the four different radii $0.5$, $1$, $2$, and $4$. Plot your results. Make sure your neurons have the same (relative, i.e., scaled by the radius) $x$-intercepts and maximum rates across all experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q1b():\n",
    "    # Calulate RMSE for different radii\n",
    "    radii = [2 ** power for power in range(-1, 3)]\n",
    "    rmses = []\n",
    "    for radius in radii:\n",
    "        tuning_x, activities, targets, decoded, rmse = q1_ensemble(radius=radius)\n",
    "        rmses.append(rmse)\n",
    "\n",
    "    # Plot RMSE vs. radius\n",
    "    plt.figure()\n",
    "    plt.plot(radii, rmses)\n",
    "    plt.title(\"RMSE vs. radius\")\n",
    "    plt.xlabel(\"Radius\")\n",
    "    plt.ylabel(\"RMSE\")\n",
    "    plt.show()\n",
    "\n",
    "    # Calculate y=mx+b\n",
    "    m = (rmses[-1] - rmses[0]) / (radii[-1] - radii[0])\n",
    "    b = rmses[0] - m * radii[0]\n",
    "    print(f\"RMSE = {m:.3f} * radius + {b:.3f}\")\n",
    "    print(f\"Slope: {m:.6f}, RMSE at radius 1: {rmses[1]:.6f}\")\n",
    "    \n",
    "q1b()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c) Discussion.** What mathematical relationship between the radius and the RMSE do you observe (write down an equation)? Explain why this is the case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For an ensemble of neurons with different radii but the same seed, the mathematical equation is $RMSE = m * R$ where slope m is the RMSE at $R=1$. This is the case because\n",
    "increasing the radius stretches the tuning curves horizontally (and decreasing the radius compresses them). As a result, the neurons are less sensitive to input \n",
    "$x$, and the same change in $x$ leads to a smaller change in firing rate. As the radius shrinks to 0, the neurons become very sensitive, and the error also approaches 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**d) RMSE and refractory period.** What happens to the RMSE and the tuning curves as $\\tau_\\mathrm{ref}$ changes between $1$ and $5\\,\\mathrm{ms}$? Plot the tuning curves for at least four different $\\tau_\\mathrm{ref}$ and produce a plot showing the RMSE over $\\tau_\\mathrm{ref}$. Again, make sure to use the same neuron ensemble parameters in all your trials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q1d():\n",
    "    # Calulate RMSE for different refractory periods\n",
    "    tau_refs = np.linspace(0.001, 0.005, 4) # 1 ms to 5 ms\n",
    "    tuning_xs = []\n",
    "    activitiess = []\n",
    "    rmses = []\n",
    "    for tau_ref in tau_refs:\n",
    "        tuning_x, activities, targets, decoded, rmse = q1_ensemble(tau_ref=tau_ref)\n",
    "        tuning_xs.append(tuning_x)\n",
    "        activitiess.append(activities)\n",
    "        rmses.append(rmse)\n",
    "\n",
    "    # Plot the tuning curves\n",
    "    fig, axs = plt.subplots(1, 4, figsize=(20, 5))\n",
    "    for i in range(4):\n",
    "        axs[i].plot(tuning_xs[i], activitiess[i])\n",
    "        axs[i].set_title(f\"Tuning curves for tau_ref = {tau_refs[i]:.4f}\")\n",
    "    fig.supxlabel(\"Input x\")\n",
    "    fig.supylabel(\"Firing rate (Hz)\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Plot RMSE vs. tau_ref\n",
    "    plt.figure()\n",
    "    plt.plot(tau_refs, rmses)\n",
    "    plt.title(\"RMSE vs. tau_ref\")\n",
    "    plt.xlabel(\"tau_ref\")\n",
    "    plt.ylabel(\"RMSE\")\n",
    "    plt.show()\n",
    "    \n",
    "q1d()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**e) RMSE and membrane time constant.** What happens to the RMSE and the tuning curves as $\\tau_\\mathrm{RC}$ changes between $10$ and $100\\,\\mathrm{ms}$? Plot the tuning curves for at least four different $\\tau_\\mathrm{RC}$ and produce a plot showing the RMSE over $\\tau_\\mathrm{RC}$.  Again, make sure to use the same neuron ensemble parameters in all your trials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q1e():\n",
    "    # Calulate RMSE for different membrane time constants\n",
    "    tau_rcs = np.linspace(0.01, 0.1, 4) # 10 ms to 100 ms\n",
    "    tuning_xs = []\n",
    "    activitiess = []\n",
    "    rmses = []\n",
    "    for tau_rc in tau_rcs:\n",
    "        tuning_x, activities, targets, decoded, rmse = q1_ensemble(tau_rc=tau_rc)\n",
    "        tuning_xs.append(tuning_x)\n",
    "        activitiess.append(activities)\n",
    "        rmses.append(rmse)\n",
    "\n",
    "    # Plot the tuning curves\n",
    "    fig, axs = plt.subplots(1, 4, figsize=(20, 5))\n",
    "    for i in range(4):\n",
    "        axs[i].plot(tuning_xs[i], activitiess[i])\n",
    "        axs[i].set_title(f\"Tuning curves for tau_ref = {tau_rcs[i]:.4f}\")\n",
    "    fig.supxlabel(\"Input x\")\n",
    "    fig.supylabel(\"Firing rate (Hz)\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Plot RMSE vs. tau_rc\n",
    "    plt.figure()\n",
    "    plt.plot(tau_rcs, rmses)\n",
    "    plt.title(\"RMSE vs. tau_ref\")\n",
    "    plt.xlabel(\"tau_ref\")\n",
    "    plt.ylabel(\"RMSE\")\n",
    "    plt.show()\n",
    "    \n",
    "q1e()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**f) Discussion.** Discuss the last two results. Describe what happens to the tuning curves as $\\tau_\\mathrm{ref}$ and $\\tau_\\mathrm{RC}$ change (you do not need to come up with a mathematical relationship here). Explain why the change in tuning curve shape influences the RMSE in the way you observe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As $\\tau_{ref}$ increases from 1 ms to 5 ms, the top of the tuning curves become more rounded. However, as $\\tau_{rc}$ increases from 10 ms to 100 ms, the bottom of the tuning curves become more straight. The RMSE decreases as the tuning curves become less rounded / more straight because the identity relationship is linear ($x = \\hat{x}$), so linear tuning curves are better able to capture that information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Connecting neurons\n",
    "\n",
    "**a) Computing the identity function.** Show the input value and the decoded values from the two  ensembles in three separate plots. Run the simulation for $0.5\\,\\mathrm{s}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q2_ensemble(tau_rc=0.02, tau_ref=0.002, radius=1, func=None, sim_time=0.5, seed=0):\n",
    "    # Generate the 1D network\n",
    "    model = nengo.Network()\n",
    "    with model:\n",
    "        a = nengo.Ensemble(n_neurons=100,                                   # 100 neurons\n",
    "                           dimensions=1,                                    # 1-dimensional space\n",
    "                           intercepts=nengo.dists.Uniform(-1, 1),           # x-intercepts between -1 and 1\n",
    "                           max_rates=nengo.dists.Uniform(100, 200),         # max firing rates between 100 and 200 Hz\n",
    "                           neuron_type=nengo.neurons.LIF(tau_rc=tau_rc, \n",
    "                                                         tau_ref=tau_ref),  # LIF neurons\n",
    "                           radius=radius,                                   # radius\n",
    "                           seed=seed)                                       # random seed\n",
    "        \n",
    "        b = nengo.Ensemble(n_neurons=50,                                    # 50 neurons\n",
    "                           dimensions=1,                                    # Everything else is the same as above\n",
    "                           intercepts=nengo.dists.Uniform(-1, 1),\n",
    "                           max_rates=nengo.dists.Uniform(100, 200),\n",
    "                           neuron_type=nengo.neurons.LIF(tau_rc=tau_rc, \n",
    "                                                         tau_ref=tau_ref),\n",
    "                           radius=radius,\n",
    "                           seed=seed)\n",
    "\n",
    "        # Create a step-function input that is a value of 1 for 0.1 < t < 0.4 seconds, and otherwise is zero\n",
    "        input = nengo.Node(lambda t: 0.0 if t < 0.1 else (1.0 if t < 0.4 else 0.0))\n",
    "        \n",
    "        # Connect with a post-synaptic time constant of 10ms\n",
    "        nengo.Connection(pre=input, post=a, synapse=0.01)\n",
    "        if func is None:\n",
    "            nengo.Connection(pre=a, post=b, synapse=0.01)\n",
    "        else:\n",
    "            nengo.Connection(pre=a, post=b, function=func, synapse=0.01)\n",
    "\n",
    "        # Probes use a synaptic filter of 10 ms\n",
    "        in_probe = nengo.Probe(input)\n",
    "        a_probe = nengo.Probe(a, synapse=0.01)\n",
    "        b_probe = nengo.Probe(b, synapse=0.01)\n",
    "\n",
    "    # Run the simulation for some time\n",
    "    with nengo.Simulator(model) as sim:\n",
    "        sim.run(sim_time)\n",
    "\n",
    "    # Plot the results\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(15, 5), sharey=True)\n",
    "    axs[0].plot(sim.trange(), sim.data[in_probe])\n",
    "    axs[0].set_title(\"Input\")\n",
    "    axs[1].plot(sim.trange(), sim.data[a_probe])\n",
    "    axs[1].set_title(\"A\")\n",
    "    axs[2].plot(sim.trange(), sim.data[b_probe])\n",
    "    axs[2].set_title(\"B\")\n",
    "    plt.show()\n",
    "\n",
    "q2_ensemble()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b) Computing an affine transformation.** Make a new version of the model where instead of computing the identity function, it computes $y(t) = 1 - 2x(t)$. Show the same graphs as in part (a)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_q2b(x):\n",
    "    return 1 - 2 * x[0]\n",
    "q2_ensemble(func=func_q2b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Dynamics\n",
    "\n",
    "**a) Transforming the dynamical system.** Rewrite the linear dynamical system describing the integrator in terms of $\\frac{\\mathrm{d}\\vec x(t)}{\\mathrm{d}t} = \\mathbf{A} \\mathbf{x} + \\mathbf{B} \\mathbf{u}$, i.e., write down the matrices $\\mathbf{A}$ and $\\mathbf{B}$ (you can just use the equations from class, you do not have to re-derive the equations) What are the matrices $\\mathbf{A}'$ and $\\mathbf{B}'$ we have to use when implementing this system using the recurrent connection post-synaptic filter?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From lecture notes, an integrator is defined as the dynamical system:\n",
    "$$\\frac{\\mathrm{d}\\vec x(t)}{\\mathrm{d}t} = \\mathbf{u}$$\n",
    "\n",
    "Therefore, the matrices are:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    \\mathbf{A} &= \\mathbf{0} \\\\\n",
    "    \\mathbf{B} &= \\mathbf{I}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "The neural implementation of LTI systems has the transformation:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    \\mathbf{A}^\\prime &= \\tau\\mathbf{A} + \\mathbf{I} \\\\\n",
    "    \\mathbf{B}^\\prime &= \\tau\\mathbf{B}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "So our matrices become:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    \\mathbf{A}^\\prime &= \\tau\\mathbf{0} + \\mathbf{I} = \\mathbf{I} \\\\\n",
    "    \\mathbf{B}^\\prime &= \\tau\\mathbf{I}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Using the longer time constant for $\\tau$ (50ms), the 1-dimensional transforms are:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    a^\\prime &= 1 \\\\\n",
    "    b^\\prime &= 0.05\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b) Integrator using spiking neurons.**  Show the input, the ideal integral, and the value represented by the ensemble when the input is a value of $0.9$ from $t=0.04$ to $t=1.0$ (and $0$ for other times). Run the simulation for $1.5\\,\\mathrm{s}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q3_ensemble(input_func, neuron_type=nengo.neurons.LIF, tau_rc=0.02, tau_ref=0.002, radius=1, sim_time=0.5, seed=0):\n",
    "    # Generate the 1D network\n",
    "    model = nengo.Network()\n",
    "    with model:\n",
    "        a = nengo.Ensemble(n_neurons=200,                               # 200 neurons\n",
    "                           dimensions=1,                                # Everything else is the same\n",
    "                           intercepts=nengo.dists.Uniform(-1, 1),\n",
    "                           max_rates=nengo.dists.Uniform(100, 200),\n",
    "                           neuron_type=neuron_type(tau_rc=tau_rc,       # LIF or LIFRate neurons\n",
    "                                                   tau_ref=tau_ref),\n",
    "                           radius=radius,\n",
    "                           seed=seed)\n",
    "        \n",
    "        input = nengo.Node(input_func)\n",
    "        \n",
    "        # Build the connections\n",
    "        nengo.Connection(pre=a, post=a, transform=[[1]], synapse=0.05)          # Recurrent connection (transform = 1, œÑ = 50ms)\n",
    "        nengo.Connection(pre=input, post=a, transform=[[0.05]], synapse=0.005)  # Input connection (transform = 0.05, œÑ = 5ms)\n",
    "\n",
    "        # Probes use a synaptic filter of 10 ms\n",
    "        in_probe = nengo.Probe(input)\n",
    "        a_probe = nengo.Probe(a, synapse=0.01)\n",
    "\n",
    "    # Run the simulation for some time\n",
    "    with nengo.Simulator(model) as sim:\n",
    "        sim.run(sim_time)\n",
    "\n",
    "    # Calculate the ideal integral\n",
    "    ideal_integral = np.cumsum(sim.data[in_probe]) * 0.001\n",
    "\n",
    "    # Plot the results\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(12, 5), sharey=True)\n",
    "    axs[0].plot(sim.trange(), sim.data[in_probe])   # Input\n",
    "    axs[0].set_title(\"Input\")\n",
    "    axs[0].set_xlabel(\"Time (s)\")\n",
    "    axs[0].set_ylabel(\"Value\")\n",
    "\n",
    "    axs[1].plot(sim.trange(), sim.data[a_probe], label=\"Simulated\")\n",
    "    axs[1].plot(sim.trange(), ideal_integral, label=\"Ideal\")\n",
    "    axs[1].legend()\n",
    "    axs[1].set_title(\"Output\")\n",
    "    axs[1].set_xlabel(\"Time (s)\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.9 from t = 0.04 to t = 1.0 (and 0 for other times)\n",
    "input_q3b = lambda t: 0.0 if t < 0.04 else (0.9 if t < 1.0 else 0.0)\n",
    "\n",
    "# Run the simulation for 1.5s\n",
    "q3_ensemble(input_func=input_q3b, sim_time=1.5, seed=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c) Discussion.** What is the expected ideal result, i.e., if we just mathematically computed the integral of the input, what is the equation describing the integral? How does the simulated output compare to that ideal?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ideal integral is:\n",
    "\n",
    "$$\n",
    "\t\\int_{0}^{t} u(t^\\prime) \\,dt^\\prime = \\begin{cases}\n",
    "\t\t0 & \\text{if } t < 0.04 \\,, \\\\\n",
    "\t\t0.9(t - 0.04) & \\text{if } 0.04 \\le t < 1 \\,, \\\\\n",
    "\t\t0.864 & \\text{if } 1 \\le t \\,.\n",
    "\t\\end{cases}\n",
    "$$\n",
    "\n",
    "The simulated output mostly matchs the ideal output, although there are 3 main deviations:\n",
    "\n",
    "1. It has a lot of high frequency noise because the neurons use the spiking LIF model. This error can be reduced by increasing the number of neurons.\n",
    "2. The simulated output is a bit higher than the ideal output because the time constants don't match. When $\\tau$ was changed to 50 ms for the input-ensemble connection (to match the recurrent connection), the average simulated output was much closer to the ideal.\n",
    "3. The random seed determines the location/coverage of the tuning curves, which affects how well the signal can be decoded. For some seeds, the ramp part of the output is very close to the ideal, while other seeds are better at the horizontal part."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**d) Simulation using rate neurons.** Change the neural simulation to rate mode. Re-run the simulation in rate mode. Show the resulting plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the simulation for 1.5s\n",
    "q3_ensemble(input_func=input_q3b, neuron_type=nengo.neurons.LIFRate, sim_time=1.5, seed=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**e) Discussion.** How does this compare to the result in part (b)? What deviations from the ideal do you still observe? Where do those deviations come from?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since d) uses rate neurons instead of spiking neurons, there's no longer any high-frequency noise. However, 2 deviations still remain:\n",
    "\n",
    "1. Due to a mismatch in time constants, the simulated outputs have a distinct LIF shape at sharp changes (when a neuron turns on). This deviation is greatly reduced when the two time constants are the same, and the simulated output looks more like a linear approximation.\n",
    "2. The random seed still affects the distribution of the tuning curves, so some decodings are closer to the ideal than others. This deviation is reduced when more neurons are used (for example 1000 instead of 200)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**f) Integration of a shorter input pulse.** Returning to spiking mode, change the input to be a value of $0.9$ from $t=0.04$ to $0.16$. Show the same plots as before (the input, the ideal, and the value represented by the ensemble over $1.5\\,\\mathrm{s}$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.9 from t = 0.04 to t = 0.16 (and 0 for other times)\n",
    "input_q3f = lambda t: 0.0 if t < 0.04 else (0.9 if t < 0.16 else 0.0)\n",
    "\n",
    "# Run the simulation for 1.5s\n",
    "q3_ensemble(input_func=input_q3f, sim_time=1.5, seed=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**g) Discussion.** How does this compare to (b)? What is the ideal equation? Does it work as intended? If not, why is it better or worse?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f) looks similar to b) in that they have similar sources of error. Both simulated outputs go above the ideal output at the start, and stay above it at a constant distance for the remainder of the output. However, f) seems to have slightly higher amplitude noise during the constant portion.\n",
    "\n",
    "The ideal integral becomes:\n",
    "\n",
    "$$\n",
    "\t\\int_{0}^{t} u(t^\\prime) \\,dt^\\prime = \\begin{cases}\n",
    "\t\t0 & \\text{if } t < 0.04 \\,, \\\\\n",
    "\t\t0.9(t - 0.04) & \\text{if } 0.04 \\le t < 0.16 \\,, \\\\\n",
    "\t\t0.108 & \\text{if } 0.16 \\le t \\,.\n",
    "\t\\end{cases}\n",
    "$$\n",
    "\n",
    "It does work as intended as it's able to represent the ideal integral to some degree. However, the noise is relatively large in f) compared to b) because the range of f) is smaller. Since b) makes better use of the whole range (-1, 1), it appears to have a better signal-to-noise ratio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**h) Input ramp.** Change the input to a ramp input from $0$ to $0.9$ from $t=0$ to $t=0.45$ (and $0$ for $t>0.45$). Show the same plots as in the previous parts of this question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.9 from t = 0.04 to t = 0.16 (and 0 for other times)\n",
    "input_q3h = lambda t: 0.0 if t < 0 else (2*t if t < 0.45 else 0.0)\n",
    "\n",
    "# Run the simulation for 1.5s\n",
    "q3_ensemble(input_func=input_q3h, sim_time=1.5, seed=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**i) Discussion.** What does the ensemble end up representing, and why? What is the (ideal) equation for the curve traced out by the ensemble?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ensemble ends up representing a parabolic curve followed by a constant tail because the integral of a ramp is parabolic.\n",
    "\n",
    "The ideal equation in this case is:\n",
    "\n",
    "$$\n",
    "\t\\int_{0}^{t} u(t^\\prime) \\,dt^\\prime = \\begin{cases}\n",
    "\t\t0 & \\text{if } t < 0 \\,, \\\\\n",
    "\t\tt^2 & \\text{if } 0 \\le t < 0.45 \\,, \\\\\n",
    "\t\t0.2025 & \\text{if } 0.45 \\le t \\,.\n",
    "\t\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**j) Sinusoidal input.** Change the input to $5\\sin(5t)$. Show the same plots as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.9 from t = 0.04 to t = 0.16 (and 0 for other times)\n",
    "input_q3j = lambda t: 5 * np.sin(5 * t)\n",
    "\n",
    "# Run the simulation for 1.5s\n",
    "q3_ensemble(input_func=input_q3j, sim_time=1.5, seed=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**k) Discussion.** What should the value represented by the ensemble be? Write the equation. How well does it do? What are the differences between the model's behaviour and the expected ideal behaviour and why do these differences occur?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The value represented by the ensemble should be:\n",
    "\n",
    "$$\n",
    "\t\\int_{0}^{t} u(t^\\prime) \\,dt^\\prime = \\begin{cases}\n",
    "\t\t0 & \\text{if } t < 0 \\,, \\\\\n",
    "\t\t-cos(5t)+1 & \\text{if } 0 \\le t \\,.\n",
    "\t\\end{cases}\n",
    "$$\n",
    "\n",
    "The simulated output has a significant deviation from the ideal output when the neurons saturate at output=1, but otherwise maintains a similar simusoidal shape as the ideal curve. Since the ideal curve has a range of [0, 2], saturation causes the simulated output to stop increasing when it reaches 1, but still able to decrease down to -1. As a result, the simulated curve takes on the range [-1, 1], which is exactly what the neurons are able to represent with radius 1.\n",
    "\n",
    "There are still 2 other sources of error as mentioned above:\n",
    "\n",
    "1. High-frequency noise due to the spiking LIF model\n",
    "2. An upward trend at the start of the output due to the time constant mismatch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**l) üåü Bonus question.** Implement a nonlinear dynamical system we have not seen in class (and that is not in the book). Demonstrate that it's working as expected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚úç \\<YOUR SOLUTION HERE\\>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úç <YOUR SOLUTION HERE>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
