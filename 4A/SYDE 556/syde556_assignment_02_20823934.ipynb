{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SYDE 556/750 --- Assignment 2\n",
    "**Student ID: 20823934**\n",
    "\n",
    "*Note:* Please include your numerical student ID only, do *not* include your name.\n",
    "\n",
    "*Note:* Refer to the [PDF](https://github.com/celiasmith/syde556-f22/raw/master/assignments/assignment_02/syde556_assignment_02.pdf) for the full instructions (including some hints), this notebook contains abbreviated instructions only. Cells you need to fill out are marked with a \"writing hand\" symbol. Of course, you can add new cells in between the instructions, but please leave the instructions intact to facilitate marking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import numpy and matplotlib -- you shouldn't need any other libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Fix the numpy random seed for reproducible results\n",
    "np.random.seed(18945)\n",
    "\n",
    "# Some formating options\n",
    "%config InlineBackend.figure_formats = ['svg']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Generating a random input signal\n",
    "\n",
    "## 1.1 Band-limited white noise\n",
    "\n",
    "**a) Time-domain signals.** Plot $x(t)$ for three randomly generated signals with $\\texttt{limit}$ at $5$, $10$, and $20\\,\\mathrm{Hz}$. For each of these, $\\mathtt{T}=1\\,\\mathrm{s}$, $\\mathtt{dt}=1\\,\\mathrm{ms}$ and $\\mathtt{rms}=0.5$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function that generates a randomly varying x(t) signal chosen from a band limited white noise distribution\n",
    "# Return both x(t) and X(œâ) --> both its time- and Fourier-domain representation\n",
    "def generate_signal(T, dt, rms, limit, seed):\n",
    "    \"\"\"\n",
    "    T --> The length of the signal in seconds\n",
    "    dt --> Time time step in seconds\n",
    "    rms --> The root mean square power of the signal\n",
    "    limit --> The maximum frequency of the signal\n",
    "    seed --> Random seed\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    ts = np.arange(0, T, dt)                                # Time points\n",
    "    fs_hz = np.fft.fftshift(np.fft.fftfreq(len(ts), dt))    # Frequency bins in Hz\n",
    "    fs_rad = 2 * np.pi * fs_hz                              # Frequency bins in rad/s\n",
    "\n",
    "    # Generate half of the random signal in the frequency domain\n",
    "    num_samples = len(fs_rad) // 2\n",
    "    real = np.random.normal(0, 1, num_samples)\n",
    "    imag = np.random.normal(0, 1, num_samples)\n",
    "    half_freq_signal = real + 1j * imag\n",
    "\n",
    "    # Create the full frequency signal by mirroring the half signal\n",
    "    # Note: The DC component is 0, so the mean of the time domain signal is 0\n",
    "    freq_signal = np.concatenate((half_freq_signal, np.array([0]), np.conj(np.flip(half_freq_signal))))\n",
    "\n",
    "    # Cut freq_signal so it has the same length as fs (in case len(fs) is even)\n",
    "    freq_signal = freq_signal[:len(fs_rad)]\n",
    "\n",
    "    # Limit the signal to the desired frequency range\n",
    "    freq_signal[np.abs(fs_hz) > limit] = 0\n",
    "\n",
    "    # Turn it back into the time domain\n",
    "    time_signal = np.fft.ifft(np.fft.ifftshift(freq_signal))\n",
    "\n",
    "    # Check if the time domain signal is real\n",
    "    imag_threshold = 1e-10  # Error threshold\n",
    "    if np.all(np.abs(time_signal.imag) < imag_threshold):\n",
    "        time_signal = time_signal.real\n",
    "    else:\n",
    "        raise ValueError(\"The time domain signal is not real\")\n",
    "\n",
    "    # Scale the time and frequency signals to the RMS power\n",
    "    old_rms = np.sqrt(np.mean(time_signal ** 2))\n",
    "    scaling_factor = rms / old_rms\n",
    "    time_signal *= scaling_factor\n",
    "    freq_signal *= scaling_factor\n",
    "\n",
    "    return ts, fs_rad, time_signal, freq_signal\n",
    "\n",
    "# Adapting the plotting code from the lecture notes\n",
    "def plot_signals(ts, fs_rad, time_signal, freq_signal):\n",
    "    # Calculate bandwidth by finding the highest frequency above the energy threshold\n",
    "    bandwidth = fs_rad[np.max(np.where(np.abs(freq_signal) > 1e-3))]\n",
    "\n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(6.5, 2.25))\n",
    "    ax1.plot(ts, time_signal)\n",
    "    ax1.set_xlabel('Time $t$ (s)')\n",
    "    ax1.set_ylabel('Signal x')\n",
    "    ax1.set_title('Time domain')\n",
    "\n",
    "    ax2.plot(fs_rad, np.abs(freq_signal))\n",
    "    ax2.set_xlabel('Frequency $f$ (rad/s)')\n",
    "    ax2.set_ylabel('Power spectrum $|X|$')\n",
    "    ax2.set_title('Frequency domain')\n",
    "\n",
    "    ax3.plot(fs_rad, np.abs(freq_signal))\n",
    "    ax3.set_xlabel('Frequency $f$ (rad/s)')\n",
    "    ax3.set_ylabel('Power spectrum $|X|$')\n",
    "    ax3.set_xlim(-min(20*2*np.pi, bandwidth), min(20*2*np.pi, bandwidth))\n",
    "    ax3.set_title('Frequency domain (magnified)')\n",
    "\n",
    "    fig.tight_layout(pad=0.5)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Generate and plot the signals\n",
    "for limit in [5, 10, 20]:\n",
    "    ts, fs_rad, time_signal, freq_signal = generate_signal(T=1, dt=0.001, rms=0.5, limit=limit, seed=0)\n",
    "    print(f'Bandwidth: {limit} Hz = {np.round(limit * 2 * np.pi, 1)} rad/s')\n",
    "    plot_signals(ts, fs_rad, time_signal, freq_signal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b) Average power spectrum.** Plot the average $|X(\\omega)|$ (the norm of the Fourier coefficients, or ‚Äúpower spectrum‚Äù) over $100$ signals generated with $\\mathtt{T}=1\\,\\mathrm{s}$, $\\mathtt{dt}=1\\,\\mathrm{ms}$, $\\mathtt{rms}=0.5$, and $\\mathtt{limit}=10\\,\\mathrm{Hz}$ (of course, each of these 100 signals should have a different `seed`). The plot should have the $x$-axis labeled ‚Äú$\\omega$ in radians‚Äù and the average $|X|$ value for that $\\omega$ on the $y$-axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_norm_coefficients = 0\n",
    "for i in range(100):\n",
    "    ts, fs_rad, time_signal, freq_signal = generate_signal(T=1, dt=0.001, rms=0.5, limit=10, seed=i)\n",
    "    sum_norm_coefficients += np.abs(freq_signal)\n",
    "mean_norm_coefficients = sum_norm_coefficients / 100\n",
    "\n",
    "print(f'Bandwidth: 10 Hz = {np.round(20 * np.pi, 1)} rad/s')\n",
    "plt.plot(fs_rad, mean_norm_coefficients)\n",
    "plt.xlabel('œâ in radians')\n",
    "plt.ylabel('Average |X(œâ)|')\n",
    "plt.xlim(-20*2*np.pi, 20*2*np.pi)\n",
    "plt.title('Average Norm of Fourier Coefficients over 100 signals')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Gaussian power spectrum noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**a) Time-domain signals.** Plot $x(t)$ for three randomly generated signals with `bandwidth` at $5$, $10$, and $20\\,\\mathrm{Hz}$. For each of these, $\\mathtt{T}=1\\,\\mathrm{s}$, $\\mathtt{dt}=1\\,\\mathrm{ms}$ and $\\mathtt{rms}=0.5$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify the function so the power drops off as frequency increases\n",
    "# Return both time and frequency domain signals\n",
    "def generate_signal_bandwidth(T, dt, rms, bandwidth, seed):\n",
    "    \"\"\"\n",
    "    T --> The length of the signal in seconds\n",
    "    dt --> Time time step in seconds\n",
    "    rms --> The root mean square power of the signal\n",
    "    limit --> The maximum frequency of the signal\n",
    "    seed --> Random seed\n",
    "    \"\"\"\n",
    "    ts = np.arange(0, T, dt)                                # Time points\n",
    "    fs_hz = np.fft.fftshift(np.fft.fftfreq(len(ts), dt))    # Frequency bins in Hz\n",
    "    fs_rad = 2 * np.pi * fs_hz                              # Frequency bins in rad/s\n",
    "\n",
    "    # Generate half of the random signal in the frequency domain\n",
    "    num_samples = len(fs_rad) // 2\n",
    "    half_freq_signal = np.zeros(num_samples, dtype=np.complex128)\n",
    "\n",
    "    for i in range(num_samples):\n",
    "        stdev = np.exp(-fs_rad[i]**2 / (2 * bandwidth**2))\n",
    "        real = np.random.normal(0, stdev)\n",
    "        imag = np.random.normal(0, stdev)\n",
    "        half_freq_signal[i] = real + 1j * imag\n",
    "\n",
    "    # Create the full frequency signal by mirroring the half signal\n",
    "    # Note: The DC component is 0, so the mean of the time domain signal is 0\n",
    "    freq_signal = np.concatenate((half_freq_signal, np.array([0]), np.conj(np.flip(half_freq_signal))))\n",
    "\n",
    "    # Cut freq_signal so it has the same length as fs (in case len(fs) is even)\n",
    "    freq_signal = freq_signal[:len(fs_rad)]\n",
    "\n",
    "    # Turn it back into the time domain\n",
    "    time_signal = np.fft.ifft(np.fft.ifftshift(freq_signal))\n",
    "\n",
    "    # Check if the time domain signal is real\n",
    "    imag_threshold = 1e-10  # Error threshold\n",
    "    if np.all(np.abs(time_signal.imag) < imag_threshold):\n",
    "        time_signal = time_signal.real\n",
    "    else:\n",
    "        raise ValueError(\"The time domain signal is not real\")\n",
    "\n",
    "    # Scale the time and frequency signals to the RMS power\n",
    "    old_rms = np.sqrt(np.mean(time_signal ** 2))\n",
    "    scaling_factor = rms / old_rms\n",
    "    time_signal *= scaling_factor\n",
    "    freq_signal *= scaling_factor\n",
    "\n",
    "    return ts, fs_rad, time_signal, freq_signal\n",
    "\n",
    "# Generate and plot the signals\n",
    "for bandwidth in [5, 10, 20]:\n",
    "    ts, fs_rad, time_signal, freq_signal = generate_signal_bandwidth(T=1, dt=0.001, rms=0.5, bandwidth=bandwidth, seed=0)\n",
    "    print(f'Bandwidth: {limit} Hz = {np.round(limit * 2 * np.pi, 1)} rad/s')\n",
    "    plot_signals(ts, fs_rad, time_signal, freq_signal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b) Average power spectrum.** Plot the average $|X(\\omega)|$ (the norm of the Fourier coefficients, or ‚Äúpower spectrum‚Äù) over $100$ signals generated with $\\mathtt{T}=1\\,\\mathrm{s}$, $\\mathtt{dt}=1\\,\\mathrm{ms}$, $\\mathtt{rms}=0.5$, and $\\mathtt{bandwidth}=10$ (of course, each of these 100 signals should have a different `seed`). The plot should have the $x$-axis labeled ‚Äú$\\omega$ in radians‚Äù and the average $|X|$ value for that $\\omega$ on the $y$-axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_norm_coefficients = 0\n",
    "for i in range(100):\n",
    "    ts, fs_rad, time_signal, freq_signal = generate_signal_bandwidth(T=1, dt=0.001, rms=0.5, bandwidth=10, seed=i)\n",
    "    sum_norm_coefficients += np.abs(freq_signal)\n",
    "mean_norm_coefficients = sum_norm_coefficients / 100\n",
    "\n",
    "print(f'Bandwidth: 10 Hz = {np.round(20 * np.pi, 1)} rad/s')\n",
    "plt.plot(fs_rad, mean_norm_coefficients)\n",
    "plt.xlabel('œâ in radians')\n",
    "plt.ylabel('Average |X(œâ)|')\n",
    "plt.xlim(-20*2*np.pi, 20*2*np.pi)\n",
    "plt.title('Average Norm of Fourier Coefficients over 100 signals')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Simulating a spiking neuron\n",
    "\n",
    "**a) Spike plots for constant inputs.** Plot the spike output for a constant input of $x=0$ over $1$ second. Report the number of spikes. Do the same thing for $x=1$. Use a time step of $\\Delta t = 1\\,\\mathrm{ms}$ for the simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tau_ref = 0.002 # 2 ms\n",
    "tau_rc = 0.02   # 20 ms\n",
    "\n",
    "def G_inverse(a):\n",
    "    return 1 / (1 - np.exp((tau_ref - 1/a)/(tau_rc)))\n",
    "\n",
    "def G(J):\n",
    "    if J > 1:\n",
    "        return 1 / (tau_ref - tau_rc * np.log(1 - 1/J))\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# Find alpha and J_bias such that the firing rate when x = 0 is 40 Hz and when x = 1 is 150 Hz\n",
    "# 40 = G(J = J_bias) ==> J_bias = G_inverse(40)\n",
    "# 150 = G(J = alpha + J_bias) ==> alpha + J_bias = G_inverse(150) ==> alpha = G_inverse(150) - J_bias\n",
    "J_bias = G_inverse(40)\n",
    "alpha = G_inverse(150) - J_bias\n",
    "\n",
    "def spike_train(x, e, alpha, J_bias, tau_ref, tau_rc, v_threshold=1, T=1, delta_t=0.001):\n",
    "    ts = np.arange(0, T, delta_t)\n",
    "    voltage = 0\n",
    "    refractory_countdown = 0\n",
    "    J = alpha * e * x + J_bias\n",
    "\n",
    "    spikes = []\n",
    "    voltages = []\n",
    "    for i in range(len(ts)):\n",
    "        # Make sure the voltage is non-negative\n",
    "        voltage = max(voltage, 0)\n",
    "        voltages.append(voltage)\n",
    "\n",
    "        # If not in refractory period, update the voltage\n",
    "        if refractory_countdown <= 0:\n",
    "            # If there's a spike, reset the voltage and start the countdown\n",
    "            if voltage >= v_threshold:\n",
    "                spikes.append(1)\n",
    "                voltage = 0\n",
    "                refractory_countdown = tau_ref\n",
    "\n",
    "            # If there's no spike, update the voltage\n",
    "            else:\n",
    "                spikes.append(0)\n",
    "                delta_v = (J[i] - voltage) / tau_rc # dv/dt = (J - v) / tau_rc\n",
    "                voltage += delta_v * delta_t        # dv = dv/dt * dt\n",
    "\n",
    "        # If in refractory period, only update the countdown\n",
    "        else:\n",
    "            spikes.append(0)\n",
    "            refractory_countdown -= delta_t\n",
    "\n",
    "    spikes = np.array(spikes)\n",
    "    num_spikes = sum(spikes)\n",
    "\n",
    "    return ts, spikes, num_spikes, voltages\n",
    "\n",
    "T = 1\n",
    "delta_t = 0.001\n",
    "\n",
    "x_0 = np.zeros(int(T/delta_t))\n",
    "ts, spikes, num_spikes, voltages = spike_train(x=x_0, e=1, alpha=alpha, J_bias=J_bias, tau_ref=tau_ref, tau_rc=tau_rc, T=T, delta_t=delta_t)\n",
    "print(f\"{num_spikes} spikes for x = 0, T = 1, and delta_t = 0.001\")\n",
    "plt.plot(ts, spikes)\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Spikes')\n",
    "plt.title(f'Spike Train for x = 0 and e = 1')\n",
    "plt.show()\n",
    "\n",
    "x_1 = np.ones(int(T/delta_t))\n",
    "ts, spikes, num_spikes, voltages = spike_train(x=x_1, e=1, alpha=alpha, J_bias=J_bias, tau_ref=tau_ref, tau_rc=tau_rc, T=T, delta_t=delta_t)\n",
    "print(f\"{num_spikes} spikes for x = 1, T = 1, and delta_t = 0.001\")\n",
    "plt.plot(ts, spikes)\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Spikes')\n",
    "plt.title(f'Spike Train for x = 1 and e = 1')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b) Discussion.** Does the observed number of spikes in the previous part match the expected number of spikes for $x=0$ and $x=1$? Why or why not? What aspects of the simulation would affect this accuracy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for T in [1, 10, 100, 1000]:\n",
    "    ts, spikes, num_spikes, voltages = spike_train(x=np.zeros(int(T/0.001)), e=1, alpha=alpha, J_bias=J_bias, tau_ref=tau_ref, tau_rc=tau_rc, T=T)\n",
    "    print(f\"{num_spikes} spikes for x = 0, T = {T}, and delta_t = 0.001\")\n",
    "\n",
    "for dt in [0.01, 0.001, 0.0001, 0.00001]:\n",
    "    ts, spikes, num_spikes, voltages = spike_train(x=np.zeros(int(1/dt)), e=1, alpha=alpha, J_bias=J_bias, tau_ref=tau_ref, tau_rc=tau_rc, delta_t=dt)\n",
    "    print(f\"{num_spikes} spikes for x = 0, T = 1, and delta_t = {dt}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No, the observed number of spikes are lower than the expected number, although they're similar. There are 4 main reasons why the simulation may not be accurate.\n",
    "\n",
    "1. Simulation length T: If a spike were to occur right after the simulation ends, the total count could be short by 1. It's better to run the simulation for longer so the spike frequency can be averaged over a longer period of time. As shown above, there are only 38 spikes for `T=1` (38Hz) but 38461 spikes for `T=1000` (38.461Hz), which is closer to 40Hz.\n",
    "\n",
    "2. Simulation interval delta_t: Because we're using a numerical method to approximate the integral, decreasing the simulation interval makes the estimate more accurate. As seen above, we only count 25 spikes per second for `delta_t = 0.01`, but 40 spikes per second for `delta_t = 0.00001`.\n",
    "\n",
    "3. Euler's method for approximating the integral: Euler's method is a very simple numerical integration technique. Something more complex like the 4th order Runge-Kutta method might give a better approximation for the integral.\n",
    "\n",
    "4. Neuron saturation: Although the neurons don't saturate in this example, the refractory period could reduce the number of spikes in other simulations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c) Spike plots for white noise inputs.** Plot the spike output for $x(t)$ generated using your function from part 1.1. Use $\\mathtt{T}=1\\,\\mathrm{s}$, $\\mathtt{dt}=1\\,\\mathrm{ms}$, $\\mathtt{rms}=0.5$, and $\\mathtt{limit}=30\\,\\mathrm{Hz}$. Overlay on this plot $x(t)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 1\n",
    "delta_t = 0.001\n",
    "\n",
    "ts, fs_rad, time_signal, freq_signal = generate_signal(T=T, dt=delta_t, rms=0.5, limit=30, seed=0)\n",
    "ts, spikes, num_spikes, voltages = spike_train(x=time_signal, e=1, alpha=alpha, J_bias=J_bias, tau_ref=tau_ref, tau_rc=tau_rc, T=T, delta_t=delta_t)\n",
    "\n",
    "plt.plot(ts, spikes, label='Spikes')\n",
    "plt.plot(ts, time_signal, label='Signal')\n",
    "plt.legend()\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Spikes & Signals')\n",
    "plt.title(f'Spike Train for a Noisy Input')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**d) Voltage over time.** Using the same $x(t)$ signal as in part *c)*, plot the neuron's voltage over time for the first $0.2$ seconds, along with the spikes over the same time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the first 200ms of the previous result instread of generating another noisy signal\n",
    "plt.plot(ts[:200], voltages[:200], label='Voltage')\n",
    "plt.plot(ts[:200], spikes[:200], label='Spikes')\n",
    "plt.legend()\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Voltages & Spikes')\n",
    "plt.title(f'Spike Train and Voltages')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**e) üåü Bonus question.** How could you improve this simulation (in terms of how closely the model matches actual equation) without significantly increasing the computation time? $0.5$ marks for having a good idea. Up to $1$ mark for actually implementing it and showing that it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the 4th order Runge-Kutta method instead of Euler's method\n",
    "def spike_train_runge_kutta(x, e, alpha, J_bias, tau_ref, tau_rc, v_threshold=1, T=1, delta_t=0.001):\n",
    "    ts = np.arange(0, T, delta_t)\n",
    "    voltage = 0\n",
    "    refractory_countdown = 0\n",
    "    J = alpha * e * x + J_bias\n",
    "\n",
    "    spikes = []\n",
    "    voltages = []\n",
    "\n",
    "    def f(v, j):\n",
    "        return (j - v) / tau_rc\n",
    "\n",
    "    for i in range(len(ts)):\n",
    "        # Make sure the voltage is non-negative\n",
    "        voltage = max(voltage, 0)\n",
    "        voltages.append(voltage)\n",
    "\n",
    "        # If not in refractory period, update the voltage\n",
    "        if refractory_countdown <= 0:\n",
    "            # If there's a spike, reset the voltage and start the countdown\n",
    "            if voltage >= v_threshold:\n",
    "                spikes.append(1)\n",
    "                voltage = 0\n",
    "                refractory_countdown = tau_ref\n",
    "            # If there's no spike, update the voltage using 4th order Runge-Kutta\n",
    "            else:\n",
    "                spikes.append(0)\n",
    "                k1 = f(voltage, J[i]) * delta_t\n",
    "                k2 = f(voltage + 0.5 * k1, J[i]) * delta_t\n",
    "                k3 = f(voltage + 0.5 * k2, J[i]) * delta_t\n",
    "                k4 = f(voltage + k3, J[i]) * delta_t\n",
    "                voltage += (k1 + 2 * k2 + 2 * k3 + k4) / 6\n",
    "\n",
    "        # If in refractory period, only update the countdown\n",
    "        else:\n",
    "            spikes.append(0)\n",
    "            refractory_countdown -= delta_t\n",
    "\n",
    "    spikes = np.array(spikes)\n",
    "    num_spikes = sum(spikes)\n",
    "\n",
    "    return ts, spikes, num_spikes, voltages\n",
    "\n",
    "# Vectorize the variables in the original function\n",
    "def spike_train_vectorized(x, e, alpha, J_bias, tau_ref, tau_rc, v_threshold=1, T=1, delta_t=0.001):\n",
    "    ts = np.arange(0, T, delta_t)\n",
    "    voltage = np.zeros_like(ts)\n",
    "    spikes = np.zeros_like(ts, dtype=int)\n",
    "    refractory_end = np.zeros_like(ts)\n",
    "    J = alpha * e * x + J_bias\n",
    "    \n",
    "    for i in range(1, len(ts)):  # Starting from 1 as the 0th index is initial conditions\n",
    "        if ts[i] < refractory_end[i-1]:\n",
    "            voltage[i] = 0\n",
    "            refractory_end[i] = refractory_end[i-1]\n",
    "        else:\n",
    "            delta_v = (J[i] - voltage[i-1]) / tau_rc\n",
    "            voltage[i] = voltage[i-1] + delta_v * delta_t\n",
    "            if voltage[i] >= v_threshold:\n",
    "                spikes[i] = 1\n",
    "                refractory_end[i] = ts[i] + tau_ref\n",
    "                voltage[i] = 0\n",
    "\n",
    "    num_spikes = np.sum(spikes)\n",
    "\n",
    "    return ts, spikes, num_spikes, voltages\n",
    "\n",
    "# Evaluate time efficiency\n",
    "import time\n",
    "\n",
    "def eval_runtime(func, func_name, repeats=5, delta_t=0.001):\n",
    "    runtime = 0\n",
    "    for i in range(repeats):\n",
    "        start_time = time.time()\n",
    "        ts, spikes, num_spikes, voltages = func(x=np.ones(int(1/delta_t)), e=1, alpha=alpha, J_bias=J_bias, tau_ref=tau_ref, tau_rc=tau_rc, delta_t=delta_t)\n",
    "        elapsed_time = time.time() - start_time\n",
    "        runtime += elapsed_time\n",
    "    error = np.round(abs(num_spikes - 150) / 150, 3)\n",
    "    avg_runtime = np.round(runtime / repeats * 1000, 3)\n",
    "    print(f'{func_name} --> Spikes: {num_spikes}, Error: {error}, Average runtime: {avg_runtime} ms over {repeats} iterations')\n",
    "\n",
    "eval_runtime(spike_train, \"Original\")\n",
    "eval_runtime(spike_train_runge_kutta, \"Runge-Kutta\")\n",
    "eval_runtime(spike_train_vectorized, \"Vectorized\")\n",
    "eval_runtime(spike_train, \"Sampling Interval\", delta_t=0.0001)\n",
    "eval_runtime(spike_train, \"Sampling Interval\", delta_t=0.00001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 3 main things to try for improving the simulation accuracy. From 2b), we see that increasing the simulation period T doesn't improve accuracy very much, so it doesn't need to be tried.\n",
    "\n",
    "1. Use a more complex numerical integration method like the 4th order Runge-Kutta: The results show that Runge-Kutta has the same error but a longer runtime. Although this specific method didn't work, other numerical methods might decrease the error.\n",
    "\n",
    "2. Refactor the code to only update a vector when something happens, instead of appending the result to a vector after every iteration. This modification intends to take advantage of numpy's efficient handling of arrays instead of updating a list, which is thought to be a slower operation. The results show that the error decreased slightly, but the runtime also increased, almost by the same factor. Therefore, refactoring isn't the solution.\n",
    "\n",
    "3. Decreasing the sampling interval delta_t: When `dt = 0.1ms`, the error decreases from 0.167 to 0.02. At `dt = 0.01ms`, the error disappears. Although this method increases the runtime by the same order of magnitude as the error decreases, the longest runtime is only 31ms, which is insignificant in most practical cases. Additionally, the user can choose the runtime according to how much error they're willing to tolerate, making this the most flexible option."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Simulating two spiking neurons\n",
    "\n",
    "**a) Spike plots for constant inputs.** Plot $x(t)$ and the spiking output for $x(t)=0$ (both neurons should spike at about $40$ spikes per second), as well as (in a separate plot) $x(t)=1$ (one neuron should spike at $\\approx 150$ spikes per second, and the other should not spike at all)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 1\n",
    "delta_t = 0.001\n",
    "\n",
    "# Plot x = 0\n",
    "x_0 = np.zeros(int(T/delta_t))\n",
    "ts, spikes_0p, num_spikes_0p, voltages = spike_train(x=x_0, e=1, alpha=alpha, J_bias=J_bias, tau_ref=tau_ref, tau_rc=tau_rc, T=T, delta_t=delta_t)\n",
    "ts, spikes_0n, num_spikes_0n, voltages = spike_train(x=x_0, e=-1, alpha=alpha, J_bias=J_bias, tau_ref=tau_ref, tau_rc=tau_rc, T=T, delta_t=delta_t)\n",
    "\n",
    "print(f\"{num_spikes_0p} positive spikes and {num_spikes_0n} negative spikes for x = 0\")\n",
    "plt.plot(ts, spikes_0p, label='Positive Neuron')\n",
    "plt.plot(ts, -spikes_0n, label='Negative Neuron')\n",
    "plt.plot(ts, x_0, label='Input')\n",
    "plt.legend()\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Spikes')\n",
    "plt.ylim(-1.1, 1.1)\n",
    "plt.title(f'Spike Trains for x = 0')\n",
    "plt.show()\n",
    "\n",
    "# Plot x = 1\n",
    "x_1 = np.ones(int(T/delta_t))\n",
    "ts, spikes_1p, num_spikes_1p, voltages = spike_train(x=x_1, e=1, alpha=alpha, J_bias=J_bias, tau_ref=tau_ref, tau_rc=tau_rc, T=T, delta_t=delta_t)\n",
    "ts, spikes_1n, num_spikes_1n, voltages = spike_train(x=x_1, e=-1, alpha=alpha, J_bias=J_bias, tau_ref=tau_ref, tau_rc=tau_rc, T=T, delta_t=delta_t)\n",
    "\n",
    "print(f\"{num_spikes_1p} positive spikes and {num_spikes_1n} negative spikes for x = 1\")\n",
    "plt.plot(ts, spikes_1p, label='Positive Neuron')\n",
    "plt.plot(ts, -spikes_1n, label='Negative Neuron')\n",
    "plt.plot(ts, x_1, label='Input')\n",
    "plt.legend()\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Spikes')\n",
    "plt.ylim(-1.1, 1.1)\n",
    "plt.title(f'Spike Trains for x = 1')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b) Spike plots for a sinusodial input.** Plot $x(t)$ and the spiking output for $x(t)=\\frac{1}2 \\sin(10 \\pi t)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 1\n",
    "delta_t = 0.001\n",
    "\n",
    "def x_func(t):\n",
    "    return 0.5 * np.sin(10 * np.pi * t)\n",
    "\n",
    "ts = np.arange(0, T, delta_t)\n",
    "xs = x_func(ts)\n",
    "\n",
    "ts, spikes_sp, num_spikes_sp, voltages = spike_train(x=xs, e=1, alpha=alpha, J_bias=J_bias, tau_ref=tau_ref, tau_rc=tau_rc, T=T, delta_t=delta_t)\n",
    "ts, spikes_sn, num_spikes_sn, voltages = spike_train(x=xs, e=-1, alpha=alpha, J_bias=J_bias, tau_ref=tau_ref, tau_rc=tau_rc, T=T, delta_t=delta_t)\n",
    "\n",
    "print(f\"{num_spikes_sp} positive spikes and {num_spikes_sn} negative spikes for x = 0.5sin(10œÄt)\")\n",
    "plt.plot(ts, spikes_sp, label='Positive Neuron')\n",
    "plt.plot(ts, -spikes_sn, label='Negative Neuron')\n",
    "plt.plot(ts, xs, label='Input')\n",
    "plt.legend()\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Spikes')\n",
    "plt.title(f'Spike Trains for x = 0.5sin(10œÄt)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c) Spike plot for a white noise signal.** Plot $x(t)$ and the spiking output for a random signal generated with your function for question 1.1 with $\\mathtt{T}=2\\,\\mathrm{s}$, $\\mathtt{dt}=1\\,\\mathrm{ms}$, $\\mathtt{rms}=0.5$, and $\\mathtt{limit}=5\\,\\mathrm{Hz}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 2\n",
    "delta_t = 0.001\n",
    "\n",
    "ts, fs_rad, time_signal, freq_signal = generate_signal(T=T, dt=delta_t, rms=0.5, limit=5, seed=0)\n",
    "ts, spikes_sp, num_spikes_sp, voltages = spike_train(x=time_signal, e=1, alpha=alpha, J_bias=J_bias, tau_ref=tau_ref, tau_rc=tau_rc, T=T, delta_t=delta_t)\n",
    "ts, spikes_sn, num_spikes_sn, voltages = spike_train(x=time_signal, e=-1, alpha=alpha, J_bias=J_bias, tau_ref=tau_ref, tau_rc=tau_rc, T=T, delta_t=delta_t)\n",
    "\n",
    "print(f\"{num_spikes_sp} positive spikes and {num_spikes_sn} negative spikes for a noisy signal\")\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(ts, spikes_sp, label='Positive Neuron')\n",
    "plt.plot(ts, -spikes_sn, label='Negative Neuron')\n",
    "plt.plot(ts, time_signal, label='Input')\n",
    "plt.legend()\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Spikes')\n",
    "plt.title(f'Spike Trains for a noisy signal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Computing an optimal filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**a) Document the code.** Fill in comments where there are `# !`-signs in the Python code. Make sure that your comments (where this makes sense) describe the semantics of the code and do not just repeat what is obvious from the code itself. Run the function with what you wrote for part 3 above, so that it uses the spike signal generated in 3c)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_optimal_filter(\n",
    "        # Signal generated from your white noise generator\n",
    "        x,\n",
    "        # Fourier coefficients from your white noise generator\n",
    "        X,\n",
    "        # Spike train from the previous part\n",
    "        spikes,\n",
    "        # Time step size\n",
    "        dt=1e-3\n",
    "    ):\n",
    "\n",
    "    # x and X should (effectively) be 1D-arrays\n",
    "    assert x.ndim == 1 and X.ndim == 1\n",
    "    assert x.shape[0] == X.shape[0]\n",
    "\n",
    "    # Number of time points t\n",
    "    Nt = x.size\n",
    "\n",
    "    # Make sure that \"spikes\" is a 2 x Nt array\n",
    "    assert spikes.ndim == 2\n",
    "    assert spikes.shape[0] == 2              \n",
    "    assert spikes.shape[1] == Nt\n",
    "\n",
    "    # Total simulation time = Number of time points * time step size\n",
    "    T = Nt * dt\n",
    "\n",
    "    # Nt number of time points that go from -T/2 to T/2 with step size dt\n",
    "    ts = np.arange(Nt) * dt - T / 2.0\n",
    "\n",
    "    # Nt number of frequency bins that go from -Nt/(2T) aka -Nyquist to Nt/(2T) aka +Nyquist with step size 1/T\n",
    "    # Nt / T is the sampling rate, so the Nyquist frequency is Nt / (2T)\n",
    "    fs = np.arange(Nt) / T - Nt / (2.0 * T)\n",
    "\n",
    "    # Angular velocity in rad/s = 2œÄ * frequency in Hz\n",
    "    omega = fs * 2.0 * np.pi\n",
    "\n",
    "    # Response = sum of signed spikes (spikes[0] is positive, spikes[1] is negative)\n",
    "    r = spikes[0] - spikes[1]\n",
    "\n",
    "    # Transform the response into the frequency domain so convolution becomes multiplication\n",
    "    R = np.fft.fftshift(np.fft.fft(r))\n",
    "\n",
    "    # Set the stdev of the Gaussian filter to 40, so sigma_t = 1/sigma = 25e-3\n",
    "    sigma_t = 25e-3\n",
    "\n",
    "    # The unnormalized Gaussian filter = exp(-œâ^2 * (1/œÉ)^2)\n",
    "    W2 = np.exp(-omega**2*sigma_t**2)\n",
    "\n",
    "    # Normalize the Gaussian filter so the sum of the coefficients is 1\n",
    "    W2 = W2 / sum(W2)\n",
    "\n",
    "    # The numerator of the unfiltered H --> (X R_conj)\n",
    "    CP = X*R.conjugate()\n",
    "\n",
    "    # Improve the optimal filter by filtering the numerator with a Gaussian filter --> (X R_conj) * W\n",
    "    WCP = np.convolve(CP, W2, 'same')\n",
    "\n",
    "    # The denominator of the unfiltered H --> |R|^2\n",
    "    RP = R*R.conjugate()\n",
    "\n",
    "    # Improve the optimal filter by filtering the denominator with a Gaussian filter --> |R|^2 * W\n",
    "    WRP = np.convolve(RP, W2, 'same')\n",
    "\n",
    "    # Calculates the power spectral density of the noisy signal\n",
    "    # Basically doing real^2 + imag^2 for each frequency or |X|^2\n",
    "    XP = X*X.conjugate()\n",
    "\n",
    "    # Smoothes the power spectral density by convolving it with a Gaussian filter\n",
    "    WXP = np.convolve(XP, W2, 'same')\n",
    "\n",
    "    # Compute the optimal windowed filter H = (X R_conj) * W / |R|^2 * W\n",
    "    H = WCP / WRP\n",
    "\n",
    "    # Convert the optimal filter back into the time domain and discard the imaginary components [H --> h]\n",
    "    h = np.fft.fftshift(np.fft.ifft(np.fft.ifftshift(H))).real\n",
    "\n",
    "    # Compute the decoded value x_hat by convolving the response R with the filter H in the frequency domain\n",
    "    XHAT = H*R\n",
    "\n",
    "    # Convert the decoded value back into the time domain and discard the imaginary components [XHAT --> x_hat]\n",
    "    xhat = np.fft.ifft(np.fft.ifftshift(XHAT)).real\n",
    "\n",
    "    return ts, fs, R, H, h, XHAT, xhat, XP, WXP\n",
    "\n",
    "ts, fs, R, H, h, XHAT, xhat, XP, WXP = compute_optimal_filter(x=time_signal, X=freq_signal, spikes=np.array([spikes_sp, spikes_sn]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b) Optimal filter.** Plot the time and frequency plots of the optimal filter for the signal you generated in question 3c). Make sure to use appropriate limits for the $x$-axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "axs[0].plot(ts, h)\n",
    "axs[0].set_xlabel('Time (s)')\n",
    "axs[0].set_ylabel('Filter h')\n",
    "axs[0].set_title('Optimal Filter in the Time Domain')\n",
    "axs[0].set_xlim([-0.25, 0.25])\n",
    "\n",
    "axs[1].plot(fs, H.real)\n",
    "axs[1].set_xlabel('Frequency (Hz)')\n",
    "axs[1].set_ylabel('Filter H')\n",
    "axs[1].set_title('Optimal Filter in the Frequency Domain')\n",
    "axs[1].set_xlim([-50, 50])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c) Decoded signal.** Plot the $x(t)$ signal, the spikes, and the decoded $\\hat x(t)$ value for the signal from 3c)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the original and decoded signals\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.plot(ts, time_signal, label='Original Signal')\n",
    "plt.plot(ts, xhat, label='Decoded Signal')\n",
    "\n",
    "# Plot the spikes as dots\n",
    "pos_spike_idx = np.where(spikes_sp == 1)[0]\n",
    "neg_spike_idx = np.where(spikes_sn == 1)[0]\n",
    "pos_spike_times = ts[pos_spike_idx]\n",
    "neg_spike_times = ts[neg_spike_idx]\n",
    "plt.scatter(pos_spike_times, np.ones_like(pos_spike_times), color='blue', marker='.', label='Positive Spikes')\n",
    "plt.scatter(neg_spike_times, -np.ones_like(neg_spike_times), color='red', marker='.', label='Negative Spikes')\n",
    "\n",
    "# Add legend, labels, and title\n",
    "plt.legend()\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Signal')\n",
    "plt.title('Original and Decoded Signals with Spikes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**d) Power spectra.** Plot the signal $|X(\\omega)|$, spike response $|R(\\omega)|$, and filtered signal $|\\hat X(\\omega)|$ power spectra for the signal from 3c)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the power spectra\n",
    "X_power = np.abs(freq_signal)   # |X(w)|\n",
    "R_power = np.abs(R)             # |R(w)|\n",
    "XHAT_power = np.abs(XHAT)       # |XHAT(w)|\n",
    "\n",
    "# Plot the power spectra\n",
    "plt.plot(fs, X_power, label='$|X(\\\\omega)|$')\n",
    "plt.plot(fs, XHAT_power, label='$|\\\\hat{X}(\\\\omega)|$')\n",
    "plt.plot(fs, R_power, label='$|R(\\\\omega)|$')\n",
    "plt.legend()\n",
    "plt.title('Power Spectra')\n",
    "plt.xlabel('Frequency (Hz)')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.xlim([-50, 50])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**e) Discussion.** How do these spectra relate to the optimal filter?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The figure in 4d) shows that $X(\\omega)$ has the most concentrated power spectra with a 5Hz bandwidth since the random signal was generated with limit = 5Hz. $\\hat{X}(\\omega)$ has a slightly spread out power spectrum and some activation between 5-30Hz, but nothing beyond that. On the other hand, $R(\\omega)$ is the most sparse near 0Hz and has a lot of power in high frequencies up to 500Hz.\n",
    "\n",
    "The role of the optimal filter is to create a smooth decoded $\\hat{x}(t)$ from a sharp/discrete $r(t)$. The power spectra show that this goal was accomplished, since the majority of the high frequency noise from $R(\\omega)$ was eliminated after filtering. Also, the fact that $\\hat{X}(\\omega)$ has a similar spectrum to $X(\\omega)$ within 5Hz is a good sign that the signal was decoded correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**f) Filter for different signal bandwidths.** Plot the optmial filter $h(t)$ in the time domain when filtering spike trains for white noise signals with different `limit` values of $2\\,\\mathrm{Hz}$, $10\\,\\mathrm{Hz}$, and $30\\,\\mathrm{Hz}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put everything in a function so the variables don't get overwritten\n",
    "def filter_limits():\n",
    "    T = 1\n",
    "    dt = 0.001\n",
    "    hs = []\n",
    "    for limit in [2, 10, 30]:\n",
    "        # Generate the random signal according to the bandwidth limit\n",
    "        ts, fs_rad, time_signal, freq_signal = generate_signal(T=T, dt=dt, rms=0.5, limit=limit, seed=0)\n",
    "\n",
    "        # Define the spike trains\n",
    "        ts, spikes_sp, num_spikes_sp, voltages = spike_train(x=time_signal, e=1, alpha=alpha, J_bias=J_bias, tau_ref=tau_ref, tau_rc=tau_rc, T=T, delta_t=delta_t)\n",
    "        ts, spikes_sn, num_spikes_sn, voltages = spike_train(x=time_signal, e=-1, alpha=alpha, J_bias=J_bias, tau_ref=tau_ref, tau_rc=tau_rc, T=T, delta_t=delta_t)\n",
    "\n",
    "        # Calculate the optimal filter h(t)\n",
    "        ts, fs, R, H, h, XHAT, xhat, XP, WXP = compute_optimal_filter(x=time_signal, X=freq_signal, spikes=np.array([spikes_sp, spikes_sn]))\n",
    "        hs.append(h)\n",
    "\n",
    "    plt.plot(ts, hs[0], label='Limit = 2 Hz')\n",
    "    plt.plot(ts, hs[1], label='Limit = 10 Hz')\n",
    "    plt.plot(ts, hs[2], label='Limit = 30 Hz')\n",
    "    plt.legend()\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.ylabel('Filter h')\n",
    "    plt.title('Optimal Filter in the Time Domain')\n",
    "    plt.xlim([-0.2, 0.2])\n",
    "    plt.show()\n",
    "\n",
    "filter_limits()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**g) Discussion.** Describe the effects on the time plot of the optimal filter as `limit` increases. Why does this happen?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As `limit` increases in `generate_signal()`, the input $x(t)$ takes on more high-frequency components, which means it has more rapid changes in the time domain. Since the optimal filter aims to minimize the decoding error between $x(t)$ and $\\hat{x}(t)$, it must also take on a higher temporal resolution to accurately capture the fast variations in the input signal. As a result, an input with a high bandwidth leads the optimal filter to also have a high bandwidth, which makes it sharper and narrower."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using post-synaptic currents as a filter\n",
    "\n",
    "\n",
    "**a) Plotting the filter for different $n$.** Plot the normalized $h(t)$ for $n=0$, $1$, and $2$, with $\\tau=7\\,\\mathrm{ms}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def c_integrand(t, n, tau):\n",
    "    return t**n * np.exp(-t/tau)\n",
    "\n",
    "# Integrated c using the trapezoidal rule\n",
    "def trapezoidal_integration(n, tau, a=0, b=1000, dt=0.001):\n",
    "    t = np.arange(a, b, dt)\n",
    "    y = c_integrand(t, n, tau)\n",
    "    integral = (y[0]/2 + np.sum(y[1:-1]) + y[-1]/2) * dt\n",
    "    return integral\n",
    "\n",
    "# h(t)\n",
    "def post_synaptic_current(n, tau, a=-0.01, b=0.075, dt=0.001):\n",
    "    t = np.arange(a, b, dt)\n",
    "    c = trapezoidal_integration(n, tau)\n",
    "    h = t**n * np.exp(-t/tau) / c\n",
    "\n",
    "    for i, time in enumerate(t):\n",
    "        if time < 0:\n",
    "            h[i] = 0\n",
    "    return t, h\n",
    "\n",
    "# Plot the post-synaptic current for n = 0, 1, and 2 with tau = 7ms\n",
    "t, h0 = post_synaptic_current(n=0, tau=0.007)\n",
    "t, h1 = post_synaptic_current(n=1, tau=0.007)\n",
    "t, h2 = post_synaptic_current(n=2, tau=0.007)\n",
    "\n",
    "plt.plot(t, h0, label=r'$\\tau$ = 7ms, n = 0')\n",
    "plt.plot(t, h1, label=r'$\\tau$ = 7ms, n = 1')\n",
    "plt.plot(t, h2, label=r'$\\tau$ = 7ms, n = 2')\n",
    "plt.legend()\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Filter Magnitude')\n",
    "plt.title('Synaptic Filter')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b) Discussion.** What two things do you expect increasing $n$ will do to $\\hat{x}(t)$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As $n$ increases, the post-synaptic current acts as more of a low-pass filter, which has a smoother but slower response curve (delayed peak magnitude). As a result, $\\hat{x}(t)$ will become smoother but also more time-shifted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c) Plotting the filter for different $\\tau$.** Plot the normalized $h(t)$ for $\\tau=2\\,\\mathrm{ms}$, $\\tau=5\\,\\mathrm{ms}$, $\\tau=10\\,\\mathrm{ms}$, $\\tau=20\\,\\mathrm{ms}$ with $n = 0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the post-synaptic current for tau = 2ms, 5ms, and 10ms with n = 0\n",
    "t, h0 = post_synaptic_current(n=0, tau=0.002)\n",
    "t, h1 = post_synaptic_current(n=0, tau=0.005)\n",
    "t, h2 = post_synaptic_current(n=0, tau=0.01)\n",
    "\n",
    "plt.plot(t, h0, label=r'$\\tau$ = 2ms, n = 0')\n",
    "plt.plot(t, h1, label=r'$\\tau$ = 5ms, n = 0')\n",
    "plt.plot(t, h2, label=r'$\\tau$ = 10ms, n = 0')\n",
    "plt.legend()\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Filter Magnitude')\n",
    "plt.title('Synaptic Filter')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**d) Discussion.** What two things do you expect increasing $\\tau$ will do to $\\hat{x}(t)$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike changing $n$, increasing $\\tau$ doesn't delay the peak but lowers its magnitude and stretches out the signal. It is also a low-pass filter, but with the peak magnitude still at t=0. As a result, $\\hat{x}(t)$ will also become smoother and a bit time-shifted, but not as much as increasing $n$ makes it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**e) Decoding a spike-train using the post-synaptic current filter.** Decode $\\hat{x}(t)$ from the spikes generated in question 3c) using an $h(t)$ with $n=0$ and $\\tau=7\\,\\mathrm{ms}$. Do this by generating the spikes, filtering them with $h(t)$, and using that as your activity matrix $A$ to compute your decoders. Plot the time and frequency plots for this $h(t)$. Plot the $x(t)$ signal, the spikes, and the decoded $\\hat{x}(t)$ value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úç <YOUR SOLUTION HERE>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**f) Deocding a spike-train representing a low-frequency signal.** Use the same decoder and $h(t)$ as in part e), but generate a new $x(t)$ with $\\mathtt{limit}=2\\,\\mathrm{Hz}$. Plot the $x(t)$ signal, the spikes, and the decoded $\\hat{x}(t)$ value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úç <YOUR SOLUTION HERE>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**g) Discussion.** How do the decodings from e) and f) compare? Explain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚úç \\<YOUR SOLUTION HERE\\>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
